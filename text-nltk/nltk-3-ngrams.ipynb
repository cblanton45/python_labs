{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: TXT-2: N-grams\n",
    "\n",
    "## Overview\n",
    "Process N-grams\n",
    "\n",
    "## Run time \n",
    "20 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import nltk\n",
    "# nltk.download('all')\n",
    "\n",
    "## downloading using command line\n",
    "#! python -m nltk.downloader all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# from os.path import expanduser\n",
    "# nltk.data.path.append( expanduser(\"~\") + \"/data/nltk_data\")\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pprint import pprint\n",
    "\n",
    "text = \"\"\"It was a sunny day! We went to the dog park.  Lots of dogs were running around.  \n",
    "My dog likes to run too; so he had a great time.  \n",
    "I bought ice cream from the ice cream truck. Yummy!\n",
    "It was a perfect sunny day!\"\"\"\n",
    "\n",
    "words = word_tokenize(text)\n",
    "words_lower = [i.lower() for i in words]\n",
    "\n",
    "print (\"raw text (\", len(text) , \") : \\n\", text)\n",
    "print (\"---\")\n",
    "print (\"words (\" , len(words), \") : \\n\",words)\n",
    "print (\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find Ngrams\n",
    "bigrams = nltk.ngrams(words, 2)\n",
    "fdist = nltk.FreqDist(bigrams)\n",
    "print(\"bigrams in raw text\") \n",
    "pprint(fdist.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## TODO : Now cleanup STOP words and calculate bigrams again\n",
    "\n",
    "stop_words_english = set(stopwords.words('english'))\n",
    "stop_words_english.update(['-', '.', ',', '#', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) \n",
    "\n",
    "cleaned = [i for i in words_lower if i not in stop_words_english]\n",
    "print (\"cleaned words (\", len(cleaned), \"):\\n\", cleaned)\n",
    "print (\"---\")\n",
    "\n",
    "## TODO : Complete the following\n",
    "## Hint : nltk.ngrams (cleaned, 2)\n",
    "bigrams = nltk.ngrams(???, ???)\n",
    "\n",
    "## TODO : \n",
    "## Hint : FreqDist (bigrams)\n",
    "fdist = nltk.FreqDist(???)\n",
    "print(\"bigrams in cleaned text:\")\n",
    "pprint(fdist.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Find top bigrams of following text\n",
    "\n",
    "* State of the Union\n",
    "* Moby Dick "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://elephantscale-public.s3.amazonaws.com/data/text/state-of-the-unions/2016-Obama.txt\n",
    "# !wget https://elephantscale-public.s3.amazonaws.com/data/text/books/moby-dick.txt\n",
    "\n",
    "# f = open('/data/text/state-of-the-unions/2014-Obama.txt')\n",
    "# f = open ('/data/text/books/moby-dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# read the text as follows\n",
    "f = open('/data/text/state-of-the-unions/2014-Obama.txt')\n",
    "# f = open ('/data/text/books/moby-dick.txt')\n",
    "text = f.read()\n",
    "\n",
    "# TODO - continue from here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - NGram Applications\n",
    "Ngrams can be used for text prediction.\n",
    "\n",
    "For example, if I am texting some one  \n",
    "__\"pleae call me ???\"__    \n",
    "What is the final word?\n",
    "\n",
    "Using ngram analytics of lots of text messages we can deduce that final word can be\n",
    "- 'back' ,  with 90% probability\n",
    "- or 'asap' , with 60% probability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
