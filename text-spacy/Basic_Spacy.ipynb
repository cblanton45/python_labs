{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab: Installing and working with spaCy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview:\n",
    "#### We will be running spaCy with 2 languages: English and German\n",
    "\n",
    "### Depends On:\n",
    "#### None\n",
    "\n",
    "### Run time:\n",
    "#### 30 mins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Installing spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Installing with pip\n",
    "\n",
    "```bash\n",
    "    $   pip install spacy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Installing models and process text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practice we are going to work mostly with `English` and a bit with `German` languages so, we have to download and install corresponding models as follow:\n",
    "\n",
    "```bash\n",
    "   $  python -m spacy download en_core_web_sm\n",
    "   $  python -m spacy download de_core_news_sm\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: To be sure spaCy works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Elephant', 'Scale', 'works', 'on', 'big', 'data', '.']\n",
      "['Elephant', 'Scale', 'arbeitet', 'mit', 'Big', 'Data', '.']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp_en = spacy.load(\"en_core_web_sm\")\n",
    "doc_en = nlp_en(u\"Elephant Scale works on big data.\")\n",
    "print([word.text for word in doc_en])  # printing every word in the text\n",
    "\n",
    "# To see the process in other languages\n",
    "nlp_de = spacy.load(\"de_core_news_sm\")\n",
    "doc_de = nlp_de(u\"Elephant Scale arbeitet mit Big Data.\")\n",
    "print([word.text for word in doc_de])  # printing every word in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4: Deriving tokens, noun chunks and sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['Elephant', 'Scale', 'works', 'on', 'big', 'data', '.', 'The', 'most', 'important', 'part', 'of', 'the', 'company', 'is', \"'\", 'human', 'resources', \"'\", 'department']\n",
      "Noun chunks:  [Elephant Scale, big data, The most important part, the company, human resources' department]\n",
      "Sentences:  [Elephant Scale works on big data., The most important part of the company is 'human resources' department]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u\"Elephant Scale works on big data. The most important part of the company is 'human resources' department\")\n",
    "\n",
    "# Tokens\n",
    "print('Tokens: ',[word.text for word in doc])\n",
    "\n",
    "# Noun chunks\n",
    "noun_chunks = list(doc.noun_chunks)\n",
    "print('Noun chunks: ',noun_chunks)\n",
    "\n",
    "# Sentences\n",
    "sentences = list(doc.sents)\n",
    "print ('Sentences: ',sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 5: Getting part-of-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elephant\n",
      "Fine-grained POS tag: PROPN\n",
      "Coarse-grained POS tag: NNP\n",
      "Word shape: Xxxxx\n",
      "Alphanumeric characters? True\n",
      "Punctuation mark? False\n",
      "million\n",
      "Is million a digit? False\n",
      "Like a number? True\n",
      "Like an email address? False\n"
     ]
    }
   ],
   "source": [
    "doc = nlp_en(u\"Elephant Scale has a revenue of $100 million\")\n",
    "es = doc[0]\n",
    "print(es)\n",
    "print(\"Fine-grained POS tag:\", es.pos_)\n",
    "print(\"Coarse-grained POS tag:\", es.tag_)\n",
    "print(\"Word shape:\", es.shape_)\n",
    "print(\"Alphanumeric characters?\", es.is_alpha)\n",
    "print(\"Punctuation mark?\", es.is_punct)\n",
    "\n",
    "mil = doc[8]\n",
    "print(mil)\n",
    "print(\"Is million a digit?\", mil.is_digit)\n",
    "print(\"Like a number?\", mil.like_num)\n",
    "print(\"Like an email address?\", mil.like_email)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
